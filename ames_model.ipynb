{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b8ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997a467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import QED,MACCSkeys,rdMolDescriptors\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317b95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(method,fp):\n",
    "    f= open('models/'+str(method)+'_'+str(fp)+'.model','rb')\n",
    "    model = pickle.load(f)\n",
    "    f.close()\n",
    "    return model\n",
    "\n",
    "def MACCS_FP(dataset, model = False):\n",
    "    MACCS_FP = pd.DataFrame()\n",
    "    if model == True:\n",
    "        for smi,endpoint in zip(dataset.smiles,dataset.endpoint):\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            MA = MACCSkeys.GenMACCSKeys(mol).ToBitString()\n",
    "            MACCS = [int(i) for i in MA]\n",
    "            MACCS.append(endpoint)\n",
    "            MACCS_FP = pd.concat([MACCS_FP,pd.DataFrame(MACCS).T])\n",
    "        MACCS_FP.drop(columns=[0],axis=1,inplace = True)\n",
    "    else:\n",
    "        for smi in dataset.smiles:\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            MA = MACCSkeys.GenMACCSKeys(mol).ToBitString()\n",
    "            MACCS = [int(i) for i in MA]\n",
    "            MACCS_FP = pd.concat([MACCS_FP,pd.DataFrame(MACCS).T])\n",
    "        MACCS_FP.drop(columns=[0],axis=1,inplace = True)\n",
    "    return MACCS_FP\n",
    "\n",
    "def RDK_FP(dataset,model = False):\n",
    "    RDK_FP = pd.DataFrame()\n",
    "    if model == True:\n",
    "        for smi,endpoint in zip(dataset.smiles,dataset.endpoint):\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            RD = Chem.RDKFingerprint(mol).ToBitString()\n",
    "            RDK = [int(i) for i in RD]\n",
    "            RDK.append(endpoint)\n",
    "            RDK_FP = pd.concat([RDK_FP,pd.DataFrame(RDK).T])\n",
    "    else:\n",
    "        for smi in dataset.smiles:\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            RD = Chem.RDKFingerprint(mol).ToBitString()\n",
    "            RDK = [int(i) for i in RD]\n",
    "            RDK_FP = pd.concat([RDK_FP,pd.DataFrame(RDK).T])\n",
    "    return RDK_FP\n",
    "\n",
    "def ECFP_FP(dataset, model = False):\n",
    "    ECFP_FP = pd.DataFrame()\n",
    "    if model == True:\n",
    "        for smi,endpoint in zip(dataset.smiles,dataset.endpoint):\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            EC = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol,2,nBits=1024).ToBitString()\n",
    "            ECFP = [int(i) for i in EC]\n",
    "            ECFP.append(endpoint)\n",
    "            ECFP_FP = pd.concat([ECFP_FP,pd.DataFrame(ECFP).T])\n",
    "    else:\n",
    "        for smi in dataset.smiles:\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            EC = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol,2,nBits=1024).ToBitString()\n",
    "            ECFP = [int(i) for i in EC]\n",
    "            ECFP_FP = pd.concat([ECFP_FP,pd.DataFrame(ECFP).T])\n",
    "    return ECFP_FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e634cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_seed = 8\n",
    "task_name = 'ames'\n",
    "tasks = ['endpoint']\n",
    "batch_size = 128\n",
    "weight_decay = 4\n",
    "learning_rate = 4\n",
    "radius = 4\n",
    "T = 2\n",
    "p_dropout = 0.1\n",
    "fingerprint_dim = 150\n",
    "per_task_output_units_num = 2\n",
    "output_units_num = len(tasks) * per_task_output_units_num\n",
    "init_df = pd.read_csv('models/initialization_df.csv')\n",
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = init_df[init_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = init_df[init_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "\n",
    "\n",
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight),reduction='mean') for weight in weights]\n",
    "\n",
    "def predict_prob(best_model,test,y_value = True):\n",
    "    'Return the performance of the test validation'\n",
    "    if y_value == False:\n",
    "        test_x = pd.DataFrame(test.iloc[:,:]).values\n",
    "        y_preds = best_model.predict(test_x)\n",
    "        y_scores =  best_model.predict_proba(test_x)[:,1]\n",
    "    else:\n",
    "        test_x = pd.DataFrame(test.iloc[:,:-1]).values\n",
    "        test_y = pd.DataFrame(test.iloc[:,-1]).values\n",
    "        y_preds = best_model.predict(test_x)\n",
    "        y_scores =  best_model.predict_proba(test_x)[:,1]\n",
    "    return y_scores,y_preds\n",
    "\n",
    "def gnn_predict_prob(model, dataset,test_df_feature_dicts):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, eval_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[eval_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,test_df_feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "    \n",
    "    return  y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0027c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consensus_model_predict(gnn_model,rf_rdk_model,svm_ecfp_model,lgb_rdk_model,xgb_maccs_model,gbt_maccs_model,dataset):\n",
    "    MACCSFP = MACCS_FP(dataset)\n",
    "    RDKFP = RDK_FP(dataset)\n",
    "    ECFPFP = ECFP_FP(dataset)\n",
    "    \n",
    "    # base model\n",
    "    rf_prob = predict_prob(rf_rdk_model, RDKFP,y_value = False)[0]\n",
    "    svm_prob = predict_prob(svm_ecfp_model,ECFPFP,y_value = False)[0]\n",
    "    lgb_prob = predict_prob(lgb_rdk_model,RDKFP,y_value = False)[0]\n",
    "    xgb_prob = predict_prob(xgb_maccs_model,MACCSFP,y_value = False)[0]\n",
    "    gbt_prob = predict_prob(gbt_maccs_model,MACCSFP,y_value = False)[0]\n",
    "    \n",
    "    dataset_filname = 'predict_data'\n",
    "    dataset_df_feature_dicts = save_smiles_dicts([s for s in dataset.cano_smiles],dataset_filname)\n",
    "    gnn_prob = gnn_predict_prob(gnn_model,dataset,dataset_df_feature_dicts)[0]\n",
    "    \n",
    "    # consensus model\n",
    "    predict_proba = np.zeros((len(dataset),6))\n",
    "    predict_proba = pd.DataFrame(predict_proba)\n",
    "    consensus_model = load_model('stacking','6')\n",
    "#    consensus_model = pickle.load('stacking_6_model.model')\n",
    "    predict_proba.columns = ['rf','svm','lgb','xgb','gbt','gnn']\n",
    "    predict_proba['rf'] = rf_prob\n",
    "    predict_proba['svm'] = svm_prob\n",
    "    predict_proba['lgb'] = lgb_prob\n",
    "    predict_proba['xgb'] = xgb_prob\n",
    "    predict_proba['gbt'] = gbt_prob\n",
    "    predict_proba['gnn'] = gnn_prob\n",
    "    predict_lr_pred = consensus_model.predict(predict_proba)\n",
    "    return predict_lr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8befb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cflou/anaconda3/envs/dgl/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "/home/cflou/anaconda3/envs/dgl/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "/home/cflou/anaconda3/envs/dgl/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator SVC from version 1.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "/home/cflou/anaconda3/envs/dgl/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "/home/cflou/anaconda3/envs/dgl/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator DummyClassifier from version 1.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "/home/cflou/anaconda3/envs/dgl/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "/home/cflou/anaconda3/envs/dgl/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator GradientBoostingClassifier from version 1.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "gnn_model = torch.load('models/attentive_fp.pt')\n",
    "rf_rdk_model = load_model('rf','RDK')\n",
    "svm_ecfp_model = load_model('svm','ECFP')\n",
    "lgb_rdk_model = load_model('lgb','RDK')\n",
    "xgb_maccs_model = load_model('xgb','MACCS')\n",
    "gbt_maccs_model = load_model('gbt','MACCS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde98b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of successfully processed smiles:  1469\n",
      "0 compounds cannot be featured\n"
     ]
    }
   ],
   "source": [
    "#dgm_raw_filename = \"/home/cflou/Project/ames/model/data/ames_predict/ames_pos_new_comps.csv\"\n",
    "dgm_raw_filename = \"data/external_set.csv\"\n",
    "dgm_feature_filename = dgm_raw_filename.replace('.csv','.pickle')\n",
    "dgm_filename = dgm_raw_filename.replace('.csv','')\n",
    "dgm_smiles_tasks_df = pd.read_csv(dgm_raw_filename)\n",
    "dgm_smilesList = dgm_smiles_tasks_df.smiles.values\n",
    "dgm_remained_smiles = []\n",
    "dgm_canonical_smiles_list = []\n",
    "for smiles in dgm_smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        dgm_canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        dgm_remained_smiles.append(smiles)\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(dgm_remained_smiles))\n",
    "dgm_smiles_tasks_df = dgm_smiles_tasks_df[dgm_smiles_tasks_df[\"smiles\"].isin(dgm_remained_smiles)]\n",
    "dgm_smiles_tasks_df['cano_smiles'] =dgm_canonical_smiles_list\n",
    "dgm_smilesList = [smiles for smiles in dgm_canonical_smiles_list]\n",
    "if os.path.isfile(dgm_feature_filename):\n",
    "    dgm_feature_dicts = pickle.load(open(dgm_feature_filename, \"rb\" ))\n",
    "else:\n",
    "    dgm_feature_dicts = save_smiles_dicts(dgm_smilesList,dgm_filename)\n",
    "    \n",
    "dgm_remained_df = dgm_smiles_tasks_df[dgm_smiles_tasks_df[\"cano_smiles\"].isin(dgm_feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "dgm_uncovered_df = dgm_smiles_tasks_df.drop(dgm_remained_df.index)\n",
    "print(str(len(dgm_uncovered_df.cano_smiles))+' compounds cannot be featured')\n",
    "dgm_remained_df = dgm_remained_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9abd5b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dicts file saved as predict_data.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cflou/anaconda3/envs/dgl/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "dgm_con_pred = consensus_model_predict(gnn_model,rf_rdk_model,svm_ecfp_model,lgb_rdk_model,xgb_maccs_model,gbt_maccs_model,\n",
    "                                     dgm_remained_df\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1a6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit import DataStructs\n",
    "\n",
    "app_do = pd.read_csv('models/applicability_domain.csv')\n",
    "molset_train = [Chem.MolFromSmiles(smi) for smi in app_do.smiles]\n",
    "fps_train = [rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024) for mol in molset_train]\n",
    "ad = 0.0880+4*0.0625\n",
    "\n",
    "def application_domain(ad,dataset,fps_train):\n",
    "    ap_domain = []\n",
    "    for smi in dataset.smiles:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        fps_test = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)\n",
    "        sim = []\n",
    "        for j in fps_train:\n",
    "            similarity=DataStructs.FingerprintSimilarity(fps_test,j)\n",
    "            sim.append(similarity)\n",
    "        top = sorted(sim,reverse = True)[0:5]\n",
    "        if min(top) > ad:\n",
    "            ap_domain.append(1)\n",
    "        else:\n",
    "            ap_domain.append(0)\n",
    "    return ap_domain\n",
    "\n",
    "ap = application_domain(ad,dgm_remained_df,fps_train)\n",
    "dgm_remained_df['pred_values'] = dgm_con_pred\n",
    "dgm_remained_df['ad'] = ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e04d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm_remained_df.to_csv('predict_results/external_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d8123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
